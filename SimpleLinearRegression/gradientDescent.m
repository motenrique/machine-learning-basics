function theta = gradientDescent(X, y, alpha, iterations)
%Computes the Gradient Descent for dataset.
%X and y represent the data, alpha represents the step size for gradient
%and iterations is the number of times to run the update for theta

%initialize the size of data set
m = length(y);

%We want to save the cost function values over each iteration, we can use the following variable
J_CostHistory = zeros(iterations, 1);

%Complete the calculation for gradient descent over the number of iterations
for iteration = 1:iterations

end

end
